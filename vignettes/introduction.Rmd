---
title: "Introduction to Principal Surrogate Evaluation in R"
author: "Michael C Sachs"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: rmarkdown::html_vignette
bibliography: psreferences.bib
vignette: >
  %\VignetteIndexEntry{introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r knitup, include = FALSE}
library(knitr)
library(printr)
set.seed(205)
```

# Methods

## Introduction

A valid surrogate endpoint can be used as a primary endpoint for evaluating treatments in phase I-II clinical trials and for predicting phase III treatment effects without requiring large and costly efficacy trials. A surrogate is considered to be valid if it provides reliable predictions of treatment effects on the clinical endpoint of interest. @Frangakis02 introduced the concept of principal stratification and the definition of a principal surrogate (PS). Informally, a post-treatment intermediate response variable is a principal surrogate if causal effects of the treatment on the clinical outcome only exist when causal effects of the treatment on the intermediate variable exist. 

The goal of PS evaluation is to compare and predict the clinical outcomes conditional on all possible treatment and surrogate combinations of interest. The combinations of interest are called the principal strata and they include a set of unobservable counterfactual responses: responses that would have occured under a set of condtions counter to the observed conditions. To finesse this problem of unobservable responses, a variety of clever trial designs and estimation approaches have been proposed. Several of these have been implemented in the `pseval` package. 


## Notation

Let $Z_i$ be the treatment indicator for subject $i$, where 0 indicates the control or standard treatment, and 1 indicates the experimental treatment. We currently only allow for two levels of treatment and assume that the treatment assigments are randomized. Let $S_i$ be the observed value of the intermediate response for subject $i$. Since $S_i$ can be affected by treatment, there are two naturally occuring counterfactual values of $S_i$: $S_i(1)$ under treatment, and $S_i(0)$ under control. Let $s_z$ be the realization of the random variable $S(z)$. The outcome of interest is denoted $Y_i$. We consider the counterfactual values of $Y_i(0)$ and $Y_i(1)$. We allow for both binary and time-to-event outcomes, thus $Y_i$ may be a vector containing a time variable and an event/censoring indicator, i.e. $Y_i = (T_i, C_i)$ where $C_i = 1$ if $T_i$ is an event time, and $C_i = 0$ if $T_i$ is a censoring time. 


## Estimands 

Criteria for $S$ to be a good surrogate are based on risk estimands that condition on the potential intermediate responses. The risk is defined as a mapping $g$ of the cumulative distribution function of $Y(z)$ condtional on the intermediate responses. Currently we focus only on marginal risk estimands which condition only on $S(1)$: 

$$
risk_1(s_1) = g\left\{F_{s_1}\left[Y(1) | S(1) = s_1\right]\right\}, \\
risk_0(s_1) = g\left\{F_{s_1}\left[Y(0) | S(1) = s_1\right]\right\}.
$$

For instance, for a binary outcome, the risk function may simply be the probability $risk_z(s_1) = P(Y(z) = 1 | S(1) = s_1)$, or for a time-to-event outcome the risk function may be the cumulative distribution function $risk_z(s_1) = P(Y(z) \leq t | S(1) = s_1)$. Specification of the distributions of $Y(z) | S(1)$ determines the likelihood, we will denote this as $f(y | \beta, s_1, z)$. If $S(1)$ were fully observed, simple maximum likelihood estimation could be used. The key challenge in estimating these risk estimands is solving the problem of conditioning on counterfactual values that are not observable for at least a subset of subjects in a randomized trial. This involves integrating out missing values based on some models and/or set of assumptions. Namely, $S(1)$ is unobserved for all subjects who received treatment 0. 

## Augmentation and Assumptions

We first make two standard assumptions: 

- Stable Unit Treatment Value Assumption (SUTVA): Observations on the independent units in the trial should be unaffected by the treatment assignment of other units. 
- Ignorable Treatment Assignment: The observed treatment assignment does not change the counterfactual clinical outcome. 

Now to estimate the missing $S(1)$ values among those with $Z = 0$, we focus on three trial augmentations: Baseline immunogenicity predictor (BIP), closeout placebo vaccination (CPV), and baseline surrogate measurement (BSM). For details on these augmentations, we refer you to @Follmann06, @Gilbert08, @Gabriel14, and @Gabriel15b. 

### BIP

Briefly, a BIP $W$ is any baseline measurement or set of measurements that is highly correlated with $S$, and is unlikely to be associated with the clinical outcome after conditioning on $S$, i.e. $Y \perp W | S(1)$. The BIP $W$ is used to integrate out the missing $S(1)$ among those with $Z = 0$ based on a model for $S(1) | W$ that is estimated among those with $Z = 1$. We describe how this model is used in the next section. 

### CPV

Under a CPV augmented design, control recipients that do not have events at the end of the follow-up period are given the experimental treatment. Then their intermediate response is measured at some time post treatment. This measurement is then used as a direct integration for the missing $S(1)$. 

### BSM

@Gabriel14 suggested the baseline augmentation BSM, which is a pre-treatment measurement of the candidate PS, denoted $S_B$. The BSM may be a good predictor of $S(1)$ without any further assumptions. It can be used in the same way as a BIP. Alternatively you transform $S(1) - S_B$ as the candidate surrogate, further increasing the assocation with the BSM/BIP. 

## Estimated Maximum Likelihood

Let $f(y | \beta, s_1, z)$ denote the density of $Y | S(1), Z$ with parameters $\beta$. Further let $R_i$ denote the indicator for missingness in $S_i(1)$. We proceed to estimate $\beta$ by maximizing

$$
\prod_{i = 1}^n \left\{f(Y_i | \beta, S_i(1), Z_i)\right\}^R_i \left\{\int f(Y_i | \beta, s, Z_i) \, d \hat{F}_{S(1) | W}(s | W_i)\right\}^{1 - R_i}
$$

with respect to $\beta$. 

This procedure is called estimated maximum likelihood (EML) and was developed in @Pepe91. The key idea is that we are averaging the likelihood contributions for subjects missing $S(1)$ with respect to the estimated distribution of $S(1) | W$. A BIP $W$ that is strongly associated with $S(1)$ is needed for adequate performance. Closed-form inference is not available for EML estimates, thus we recommend use of the bootstrap for estimation of standard errors. 

## Conclusion 

The `pseval` package allows users to specify the type of augmented design that suits their data, specify the form of the risk model along with the distribution of $Y | S(1)$, and specify different integration models to estimate the distribution of $S(1) | W$. Then the likelihood can be maximized and bootstraps run. Post-estimation summaries are available to display and analyze the treatment efficacy as a function of $S(1)$. All of this is implemented with a flexible and familiar interface. 

# Package information

## Installation

`pseval` is an R package aimed at implementing existing methods for surrogate evaluation using a flexible and common interface. It is still in active development and testing. Development will take place on [the Github page](https://github.com/sachsmc/pseval), and the current version of the package can be installed as shown below. First you must install the `devtools` package, if you haven't already `install.packages("devtools")`. 

```{r eval = FALSE}
devtools::install_github("sachsmc/pseval")
```

## Usage

Here we will walk through some basic analyses from the point of view of a new R user. Along the way we will highlight the main features of `pseval`. `pseval` supports both binary outcomes and time-to-event, thus we will also need to load the `survival` package.

```{r setup}
library(pseval)
library(survival)
```

### Example dataset

First let's create an example dataset. The pseval package provides the function `generate_example_data` which takes a single argument: the sample size. 

```{r}
fakedata <- generate_example_data(n = 500)
head(fakedata)
```

The example data includes both a time-to-event outcome, a binary outcome, a surrogate, a BIP, CPV, and BSM, and a categorical version of the surrogate. The true model for the time is exponential, with parameters (intercept) = 1, S(1) = 0, Z = -0.5, S(1):Z = -1. The true model for binary is logistic, with the same parameter values. 

### The `psdesign` object

We begin by creating a `psdesign` object with the synonymous function. This is the object that combines the raw dataset with information about the study design and the structure of the data. Subsequent analysis will operate on this psdesign object. It is analogous to the `svydesign` function in the [survey](https://cran.r-project.org/web/packages/survey/) package. The first argument is the data frame where the data are stored. All subsequent arguments describe the mappings from the variable names in the data frame to important variables in the PS analysis, using the same notation as above. An optional weights argument describes the sampling weights, if any. Our first analysis will use the binary version of the outcome, with continuous $S.1$ and the BIP $X$. The object has a print method, so we can inspect the result. 

```{r psdesign}
binary.ps <- psdesign(data = fakedata, Z = Z, Y = Y.obs, S = S.obs, BIP = BIP)
binary.ps
```

The printout displays a brief description of the data, including the empirical vaccine efficacy estimate, the variables used in the analysis and their corresponding variables in the original dataset. Finally the printout invites the user to see the help page for `add_integration`, in order to add an integration model to the psdesign object, the next step in the analysis. 

### Integration models

The EML procedure requires an estimate of $F_{S(1) | W}$, this is referred to as the integration model. Let's see the help page for `add_integration`:

```{r helpimp}
?add_integration
```

For this first example, let's use the parametric integration model. We specify the mean model for $S(1) | W$ as a formula. We can add the integration model directly to the psdesign object and inspect the results. Note that in the formula, we refer to the variable names in the augmented dataset. 

```{r impp}
binary.ps <- binary.ps + integrate_parametric(S.1 ~ BIP)
binary.ps
```

We can add multiple integration models to a psdesign object, say we want a model for $S(0) | W$: 

```{r imp2}
binary.ps + integrate_parametric(S.0 ~ BIP)
```

In a future version of the package, we will allow for estimation of the joint risk estimands that depend on both $S(0)$ and $S(1)$. We can also use splines or other transformations in the formula: 

```{r imp3}
library(splines)
binary.ps + integrate_parametric(S.1 ~ BIP^2)
binary.ps + integrate_parametric(S.1 ~ bs(BIP, df = 3))
```

These are shown as examples, we will proceed with the simple linear model for integration. 


The next step is to define the risk model. 

### Risk models and likelihoods

Let's see how to add a risk model:

```{r riskhelp}
?add_riskmodel
```

Let's add a simple binary risk model using the logit link. The argument `D` specifies the number of samples to use for the simulated annealing aka empirical integration in the EML procedure. 

```{r riskbin}
binary.ps <- binary.ps + risk_binary(model = Y ~ S.1 * Z, D = 2000, risk = risk.logit)
binary.ps
```

### Estimation and Bootstrap

```{r est, cache = TRUE}
binary.est <- ps_estimate(binary.ps, method = "BFGS")
binary.boot <- ps_bootstrap(binary.est, n.boots = 10, progress.bar = FALSE, 
                            start = binary.est$estimates$par, method = "BFGS")

binary.boot
```
### Plots and summaries

```{r plot1}
plot(binary.boot, summary = "VE")
```


```{r summary}
summary(binary.boot)
```



# References


